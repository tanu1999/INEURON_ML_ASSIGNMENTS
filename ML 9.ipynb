{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e1a253f-2ecd-4c30-8bf1-0598b4e7fa60",
   "metadata": {},
   "source": [
    "1. What is feature engineering, and how does it work? Explain the various aspects of feature\n",
    "engineering in depth.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c859ce-c221-4c55-b9a0-f9617978d3c4",
   "metadata": {},
   "source": [
    "Feature engineering is the process of selecting,manipulated,and transformation raw data into feature that can be \n",
    "used in supervised learning.In order to make machine learning work well on new tasks,it might be neccessary to design\n",
    "and train better features.\n",
    "\n",
    "Feature engineering in ML consists of four main steps: Feature Creation,Transformations,Feature Extraction, and \n",
    "feature Selection.Feature engineering consists of creation,transformation,extraction, and selection of features,\n",
    "also known as variables, that are most conductive to createing an accurate ML algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d676665-7ba7-4b65-897e-cbd102b38ff0",
   "metadata": {},
   "source": [
    "2. What is feature selection, and how does it work? What is the aim of it? What are the various\n",
    "methods of function selection?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ebe704-c0af-4326-9be5-42f08c99f0dc",
   "metadata": {},
   "source": [
    "Feature selection is the process where you automatically or manually select those features which contribute most to \n",
    "your prediction variable or output in which you are intreseted in. Having irrelevant features in your data can decrease\n",
    "the accuracy of the models and make your model learn based on irrelevent features.\n",
    "\n",
    "There are three types of feature selection:\n",
    "\n",
    "    Wrapper methods(forward ,backward, and stepwise selection)\n",
    "    \n",
    "    Filter methods(ANOVA ,Pearson correlation ,variance threshoulding)\n",
    "    \n",
    "    Enbedded methods (Lasso, Ridge , Decision Tree)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3847e477-d50b-4bf1-923b-e0758d880dad",
   "metadata": {},
   "source": [
    "3. Describe the function selection filter and wrapper approaches. State the pros and cons of each\n",
    "approach?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3e06a5-79a2-4461-b4cb-ca9370194dd9",
   "metadata": {},
   "source": [
    "The main differences between the filter and wrapper methods for feature selection are: Filter method measure the \n",
    "relevance of features by their correlation with dependent variable while wrapper methods measure the usefulness of a\n",
    "subset of feature by actually training a model on it.\n",
    "\n",
    "The filter method has the fastest running time however, it does not consider feature dependencies and trends to each \n",
    "feature seperately when uivariate techniques are used. The wrapper method has the advantages of better generalization \n",
    "and robust interaction with the classifier used for feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2994085-be83-4157-b4a5-8c2f7d3848ec",
   "metadata": {},
   "source": [
    "4.\n",
    "\n",
    "i. Describe the overall feature selection process.\n",
    "\n",
    "ii. Explain the key underlying principle of feature extraction using an example. What are the most\n",
    "widely used function extraction algorithms?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1f22c3-2349-4e03-b930-21f96c3bd337",
   "metadata": {},
   "source": [
    "Feature selection is the process of reducing the number of input variables when devoloping a predictive model.It is \n",
    "desirable to reduce the number of input variables to both reduce the computational cost of modelling and, in some cases,\n",
    "to improve the performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef30e95-93ff-4a50-89a8-de856aa2a0cf",
   "metadata": {},
   "source": [
    "5. Describe the feature engineering process in the sense of a text categorization issue.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd28c82a-411d-4691-bddb-beff8a1d7da3",
   "metadata": {},
   "source": [
    "Text classification is the problem of assigning categories to text data according to its content.The most important\n",
    "part of text classification is feature engnineering : the process of creating features for a machine learing model\n",
    "from raw data  text data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c3264a-a0f2-47b6-b5cc-9ff443bdc954",
   "metadata": {},
   "source": [
    "6. What makes cosine similarity a good metric for text categorization? A document-term matrix has\n",
    "two rows with values of (2, 3, 2, 0, 2, 3, 3, 0, 1) and (2, 1, 0, 0, 3, 2, 1, 3, 1). Find the resemblance in\n",
    "cosine.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5aab1c-a13a-4378-889f-678cacdfb709",
   "metadata": {},
   "source": [
    "Cosine similarity is a metric used to measure how similar the documents are irresprectively os their size.The cosine \n",
    "similarity is advantageous because even if the two similar deocuments are far apart by the Eiclident  distance (due to\n",
    "the size of the document), chances are they may still be orianted closer together.\n",
    "\n",
    "Cosine similarity is the cosine of the angle between two n-dimensional vectors in an n-dimentional space.It is the dot \n",
    "product  of the two vectors divided by the product of the two vectors lengths (or magnitudes).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb994dff-d474-4d71-81ed-2ca980c118d5",
   "metadata": {},
   "source": [
    "7.\n",
    "\n",
    "i. What is the formula for calculating Hamming distance? Between 10001011 and 11001111,\n",
    "calculate the Hamming gap.\n",
    "\n",
    "ii. Compare the Jaccard index and similarity matching coefficient of two features with values (1, 1, 0,\n",
    "0, 1, 0, 1, 1) and (1, 1, 0, 0, 0, 1, 1, 1), respectively (1, 0, 0, 1, 1, 0, 0, 1).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04811db-2073-4e9b-b897-ef21ee8b795e",
   "metadata": {},
   "source": [
    "Thus the Hamming distance between two vectors is the number of bits we must change to change on into the other.\n",
    "Example Find the distance between the vectors 01101010 and 11011011. They differ in four places, so the Haming\n",
    "distance d(01101010,11011011) =4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1d55f0-4d46-4251-92a0-24bbc65514fa",
   "metadata": {},
   "source": [
    "8. State what is meant by 'high-dimensional data set'? Could you offer a few real-life examples?\n",
    "What are the difficulties in using machine learning techniques on a data set with many dimensions?\n",
    "What can be done about it?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6fd56f-449a-4426-8087-8b07d743a488",
   "metadata": {},
   "source": [
    "High dimension is when variable number p is higher than the sample sizes n i.e. p>n, cases. Higher dimensional data is \n",
    "referred to a data of n samples with p features, where p is larger than n.\n",
    "\n",
    "For example, tomographic imaging data, ECG data, and MEG data.One example of high dimentional data is microarray gene\n",
    "expression data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c4d838-78a3-4445-8f61-e91b7841ca80",
   "metadata": {},
   "source": [
    "9. Make a few quick notes on:\n",
    "\n",
    "1. PCA is an acronym for Personal Computer Analysis.\n",
    "\n",
    "2. Use of vectors\n",
    "\n",
    "3. Embedded technique\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19543f56-e37b-40f7-aa22-4a8d48d256c7",
   "metadata": {},
   "source": [
    "The Principal component analysis (PCA) is a technique used for identification of a smaller number of uncorrelated\n",
    "variables knowna as principal components from a larger set of data. The techique is widely used to emphasize variation \n",
    "and capture strong patterns in a data set.\n",
    "\n",
    "Vectors can be used to represent physical quantities.Most commonly in physics, vectors are used to represent \n",
    "displacement, velocity, and accelaration. Vectors are a combination of magnitude and direction, and are drawn as\n",
    "arrows \n",
    "In the context of machine learning ,  an embedding is a low-dimentional,learning continuous vector representation of \n",
    "discrete variables into which you can translate high-dimentional vectors.Generally, embeddings makes ML models more \n",
    "efficient and easier to work with, can be used with other models as well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c963ac91-5cb9-4fbe-b637-2f36636be0a6",
   "metadata": {},
   "source": [
    "10. Make a comparison between:\n",
    "\n",
    "    1. Sequential backward exclusion vs. sequential forward selection\n",
    "\n",
    "    2. Function selection methods: filter vs. wrapper\n",
    "\n",
    "    3. SMC vs. Jaccard coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f0c7c9-b20b-49a9-90ac-eb26965120be",
   "metadata": {},
   "source": [
    "Sequential floating forward selection (SFFS) starts from the empty set. After each forward step, SFFS performs \n",
    "backward steps as long as the objective function  increases. Sequential floating backward selection (SFBS) starts from \n",
    "the full set.\n",
    "\n",
    "The jaccard coefficient is a measure of the percentage of overlap between sets defined as: (5.1) where W1 and W2 are \n",
    "two sets, in our case the 1-year windows of the ego networks.The jaccard coefficent can be a value between 0 and 1,\n",
    "with 0 indication no overlap and 1 complete overlap between the sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0d2b4a-f47e-4acf-8e2a-3dcdac51d3f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
